# <center>手工实现神经网络</center>

## 一、感知器

感知器算法可以自动学习权重，使得其与输入的乘积能够决定一个神经元是否产生输出。
在输出值上定义某种转换函数，将结果转换到我们需要的分类上，这个转换函数又叫激活函数。

$w=\left[ \begin{matrix} w_1 \\ w_2 \\ w_3 \\ ... \\w_m \end{matrix} \right]$, $x=\left[ \begin{matrix} x_1 \\ x_2 \\ x_3 \\... \\x_m \end{matrix} \right]$

$z=w^T · x = w_1 · x_1 + w_2 · x_2 + w_3 · x_3 + ··· + w_m · x_m $

$\phi(z) = \begin{cases} 1 , &  z> 阈值 \\ 0 , & 其他 \end{cases}$

$w$称为权重，$x$称为输入特征，$z$称为网络输入，$\phi$则是决定输出的激活函数。

可以看到：

* 在监督训练阶段，$w$不可知，是训练和学习的目标，我们通过训练集中的已知$x$和$\phi$输出值来反推$w$的值，这个反推的过程叫做**反向传播**. 通常使用梯度下降算法。

* 在实际运行阶段和预测阶段，我们用训练好de
